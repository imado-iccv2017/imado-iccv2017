<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>ICCV2017 Workshop on Image-based Modeling of Articulated and Deformable Objects (IMADO)</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Main</div>
<div class="menu-item"><a href="index.html" class="current">Home</a></div>
<div class="menu-item"><a href="index.html#Overview">Overview</a></div>
<div class="menu-item"><a href="index.html#CFP">Call&nbsp;For&nbsp;Papers</a></div>
<div class="menu-item"><a href="index.html#Speakers">Invited&nbsp;Speakers</a></div>
<div class="menu-item"><a href="index.html#Speakers">Organizers</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>ICCV2017 Workshop on Image-based Modeling of Articulated and Deformable Objects (IMADO)</h1>
</div>
<div class="infoblock">
<div class="blockcontent">
<h3>Imortant dates:</h3>
<ul>
<li><p>Submission deadline: June 30, 2017</p>
</li>
<li><p>Acceptance notification: July 31, 2017</p>
</li>
<li><p>Workshop: October 28, 2017 </p>
</li>
</ul>
</div></div>
<h2><a name='Overview'> Overview </a></h2>
<p>Modeling and shape analysis of articulated and deformable objects (ADOs) is a challenging field of computer vision. Since the early days of computer vision, the largest part of the literature has concentrated on the modeling of static, rigid objects and structures, using stereo and multi-camera systems, inferring shape from motion, shadows, refraction, shading, photometric stereo, etc. Most of these methods are not suitable for modeling articulated and deformable objects for different reasons. On the other hand, a relatively small number of works have treated the problem of articulated and deformable object modeling, by using shape and trajectory basis analysis, feature tracking, as well as by combining simplified geometric shapes, like generalized cylinders, geons, etc.</p>
<p>In the last decade interest in 3D modelling of ADOs has been renewed as models and approaches introduced for specific problems, as for example human body modeling and human pose estimation, hand modeling and tracking, and face analysis, have become more mature allowing their use in more general and/or challenging problems. Moreover, a large number of detailed 3D models has become available, both artistically created and captured by specialized equipment, allowing the use of more sophisticated Machine Learning and Deep Learning techniques. The recent advent of the virtual and augmented reality era on one hand and the ubiquity of GPGPU computing on the other has also increased the interest in 3D modeling and tracking of ADOs for real-time applications.</p>
<p>The main focus of the workshop is on the generation of 3D models of articulated and deformable objects from images and videos. We aim to bring together and offer a forum of discussion and interaction among researchers interested in modeling, reconstruction and pose estimation techniques and favor the cross-fertilization between fields like Computer Vision, Pattern Recognition, Computer Graphics, Robotics, and Machine Learning. We believe that the workshop will give a new view on ADO 3D modeling from videos and images and thus will be interesting to 3D vision and machine learning experts on one hand, and will offer new solutions to challenging problems in computer vision, pattern recognition and computer graphics, and thus would appeal to experts in these fields on the other.</p>
<h3>Suggested topics include but are not limited to:</h3>
<ul>
<li><p>Articulated and deformable object modelling from videos</p>
</li>
<li><p>Articulated and deformable object modelling from a single image</p>
</li>
<li><p>Multi-view articulated and deformable object modelling</p>
</li>
<li><p>3D animation of articulated and deformable objects from videos</p>
</li>
<li><p>3D shape tracking</p>
</li>
<li><p>3D shape registration</p>
</li>
<li><p>Full and partial 3D shape retrieval</p>
</li>
<li><p>Sketch-based modeling and retrieval</p>
</li>
<li><p>Character modeling based on gesture drawings</p>
</li>
<li><p>Articulated object pose estimation (including human body and hand pose estimation)</p>
</li>
<li><p>3D modeling of animals</p>
</li>
<li><p>Shape analysis and synthesis</p>
</li>
<li><p>Shape similarity and correspondence</p>
</li>
<li><p>4D reconstruction</p>
</li>
<li><p>Articulated and deformable object 3D shape and pose datasets</p>
</li>
</ul>
<h2><a name='CFP'> Call for Papers </a></h2>
<p>Relevant original contributions as well as contributions that have been recently presented in other venues, including the ICCV main conference are welcome. Accepted submission will be invited for presentation during the oral and poster sessions of the workshop. </p>
<h3>Instructions</h3>
<ul>
<li><p>Submissions should follow the ICCV format (templates can be found <a href="http://iccv2017.thecvf.com/submission/main_conference/author_guidelines">here</a>)</p>
</li>
<li><p>The recommended paper length is 4-8 pages</p>
</li>
<li><p>Review process will be double blind</p>
</li>
<li><p>Official proceedings will be available</p>
</li>
</ul>
<h3>Submission Site:</h3>
<p>Cooming soon</p>
<h2><a name='Speakers'> Invited Speakers </a></h2>
<p><b> TBA soon</b></p>
<h2><a name='Organizers'> Organizers </a></h2>
<ul>
<li><p><a href="http://www.diag.uniroma1.it/~ntouskos">Valsamis Ntouskos</a> Sapienza University of Rome</p>
</li>
<li><p><a href="http://sites.google.com/site/erodola/">Emanuele Rodol√†</a> University of Lugano</p>
</li>
<li><p><a href="http://www.diag.uniroma1.it/~pirri">Fiora Pirri</a> Sapienza University of Rome</p>
</li>
<li><p><a href="http://www.inf.usi.ch/bronstein/">Michael Bronstein</a> University of Lugano</p>
</li>
</ul>
<div id="footer">
<div id="footer-text">
Page generated 2017-04-30 20:46:44 W. Europe Daylight Time, by <a href="http://jemdoc.jaboc.net/">jemdoc</a>.
</div>
</div>
</td>
</tr>
</table>
</body>
</html>
